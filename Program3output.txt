<file filename="nlp_data/d01.txt">
  <sentences>
    <sentence>
      <token>Euclid</token>
      <token>'</token>
      <token>s</token>
      <token>Elements</token>
      <token>has</token>
      <token>been</token>
      <token>referred</token>
      <token>to</token>
      <token>as</token>
      <token>the</token>
      <token>most</token>
      <token>successful</token>
      <token>and</token>
      <token>influential</token>
      <token>textbook</token>
      <token>ever</token>
      <token>written</token>
    </sentence>
    <sentence>
      <token>First</token>
      <token>set</token>
      <token>in</token>
      <token>type</token>
      <token>in</token>
      <token>Venice</token>
      <token>in</token>
      <token>1482</token>
      <token>,</token>
      <token>it</token>
      <token>is</token>
      <token>one</token>
      <token>of</token>
      <token>the</token>
      <token>very</token>
      <token>earliest</token>
      <token>mathematical</token>
      <token>works</token>
      <token>to</token>
      <token>be</token>
      <token>printed</token>
      <token>after</token>
      <token>the</token>
      <token>invention</token>
      <token>of</token>
      <token>the</token>
      <token>printing</token>
      <token>press</token>
      <token>and</token>
      <token>was</token>
      <token>estimated</token>
      <token>by</token>
      <token>Carl</token>
      <token>Benjamin</token>
      <token>Boyer</token>
      <token>to</token>
      <token>be</token>
      <token>second</token>
      <token>only</token>
      <token>to</token>
      <token>the</token>
      <token>Bible</token>
      <token>in</token>
      <token>the</token>
      <token>number</token>
      <token>of</token>
      <token>editions</token>
      <token>published</token>
      <token>,</token>
      <token>with</token>
      <token>the</token>
      <token>number</token>
      <token>reaching</token>
      <token>well</token>
      <token>over</token>
      <token>one</token>
      <token>thousand</token>
    </sentence>
    <sentence>
      <token>For</token>
      <token>centuries</token>
      <token>,</token>
      <token>knowledge</token>
      <token>of</token>
      <token>at</token>
      <token>least</token>
      <token>part</token>
      <token>of</token>
      <token>the</token>
      <token>Elements</token>
      <token>was</token>
      <token>required</token>
      <token>of</token>
      <token>all</token>
      <token>students</token>
    </sentence>
    <sentence>
      <token>Not</token>
      <token>until</token>
      <token>the</token>
      <token>20th</token>
      <token>century</token>
      <token>,</token>
      <token>by</token>
      <token>which</token>
      <token>time</token>
      <token>its</token>
      <token>content</token>
      <token>was</token>
      <token>universally</token>
      <token>taught</token>
      <token>through</token>
      <token>other</token>
      <token>school</token>
      <token>textbooks</token>
      <token>,</token>
      <token>did</token>
      <token>it</token>
      <token>cease</token>
      <token>to</token>
      <token>be</token>
      <token>considered</token>
      <token>something</token>
      <token>all</token>
      <token>educated</token>
      <token>people</token>
      <token>had</token>
      <token>read</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d02.txt">
  <sentences>
    <sentence>
      <token>The</token>
      <token>Broyden–Fletcher–Goldfarb–Shanno</token>
      <token>(</token>
      <token>BFGS</token>
      <token>)</token>
      <token>algorithm</token>
      <token>is</token>
      <token>an</token>
      <token>iterative</token>
      <token>method</token>
      <token>for</token>
      <token>solving</token>
      <token>unconstrained</token>
      <token>nonlinear</token>
      <token>optimization</token>
      <token>problems</token>
    </sentence>
    <sentence>
      <token>The</token>
      <token>BFGS</token>
      <token>method</token>
      <token>approximates</token>
      <token>Newton</token>
      <token>'</token>
      <token>s</token>
      <token>method</token>
      <token>,</token>
      <token>a</token>
      <token>class</token>
      <token>of</token>
      <token>hill-climbing</token>
      <token>optimization</token>
      <token>techniques</token>
      <token>that</token>
      <token>seeks</token>
      <token>a</token>
      <token>stationary</token>
      <token>point</token>
      <token>of</token>
      <token>a</token>
      <token>(</token>
      <token>preferably</token>
      <token>twice</token>
      <token>continuously</token>
      <token>differentiable</token>
      <token>)</token>
      <token>function</token>
    </sentence>
    <sentence>
      <token>For</token>
      <token>such</token>
      <token>problems</token>
      <token>,</token>
      <token>a</token>
      <token>necessary</token>
      <token>condition</token>
      <token>for</token>
      <token>optimality</token>
      <token>is</token>
      <token>that</token>
      <token>the</token>
      <token>gradient</token>
      <token>be</token>
      <token>zero</token>
    </sentence>
    <sentence>
      <token>Newton</token>
      <token>'</token>
      <token>s</token>
      <token>method</token>
      <token>and</token>
      <token>the</token>
      <token>BFGS</token>
      <token>methods</token>
      <token>are</token>
      <token>not</token>
      <token>guaranteed</token>
      <token>to</token>
      <token>converge</token>
      <token>unless</token>
      <token>the</token>
      <token>function</token>
      <token>has</token>
      <token>a</token>
      <token>quadratic</token>
      <token>Taylor</token>
      <token>expansion</token>
      <token>near</token>
      <token>an</token>
      <token>optimum</token>
    </sentence>
    <sentence>
      <token>These</token>
      <token>methods</token>
      <token>use</token>
      <token>both</token>
      <token>the</token>
      <token>first</token>
      <token>and</token>
      <token>second</token>
      <token>derivatives</token>
      <token>of</token>
      <token>the</token>
      <token>function</token>
    </sentence>
    <sentence>
      <token>However</token>
      <token>,</token>
      <token>BFGS</token>
      <token>has</token>
      <token>proven</token>
      <token>to</token>
      <token>have</token>
      <token>good</token>
      <token>performance</token>
      <token>even</token>
      <token>for</token>
      <token>non-smooth</token>
      <token>optimizations</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d03.txt">
  <sentences>
    <sentence>
      <token>Montgomery</token>
      <token>Castle</token>
      <token>is</token>
      <token>a</token>
      <token>stone</token>
      <token>masonry</token>
      <token>castle</token>
      <token>looking</token>
      <token>over</token>
      <token>the</token>
      <token>town</token>
      <token>of</token>
      <token>Montgomery</token>
      <token>in</token>
      <token>Powys</token>
      <token>,</token>
      <token>Wales</token>
    </sentence>
    <sentence>
      <token>It</token>
      <token>is</token>
      <token>one</token>
      <token>of</token>
      <token>many</token>
      <token>Norman</token>
      <token>castles</token>
      <token>on</token>
      <token>the</token>
      <token>border</token>
      <token>between</token>
      <token>Wales</token>
      <token>and</token>
      <token>England</token>
    </sentence>
    <sentence>
      <token>The</token>
      <token>original</token>
      <token>castle</token>
      <token>was</token>
      <token>built</token>
      <token>at</token>
      <token>the</token>
      <token>order</token>
      <token>of</token>
      <token>Roger</token>
      <token>de</token>
      <token>Montgomery</token>
      <token>,</token>
      <token>earl</token>
      <token>of</token>
      <token>Shrewsbury</token>
      <token>sometime</token>
      <token>between</token>
      <token>1071</token>
      <token>and</token>
      <token>1074</token>
    </sentence>
    <sentence>
      <token>On</token>
      <token>the</token>
      <token>rebellion</token>
      <token>of</token>
      <token>his</token>
      <token>son</token>
      <token>Robert</token>
      <token>of</token>
      <token>Belleme</token>
      <token>in</token>
      <token>1102</token>
      <token>,</token>
      <token>the</token>
      <token>castle</token>
      <token>was</token>
      <token>given</token>
      <token>to</token>
      <token>Baldwin</token>
      <token>de</token>
      <token>Boulers</token>
    </sentence>
    <sentence>
      <token>In</token>
      <token>1267</token>
      <token>Montgomery</token>
      <token>was</token>
      <token>the</token>
      <token>meeting</token>
      <token>place</token>
      <token>for</token>
      <token>treaty</token>
      <token>negotiations</token>
      <token>,</token>
      <token>where</token>
      <token>King</token>
      <token>Henry</token>
      <token>III</token>
      <token>granted</token>
      <token>Llywelyn</token>
      <token>ap</token>
      <token>Gruffudd</token>
      <token>the</token>
      <token>title</token>
      <token>of</token>
      <token>Prince</token>
      <token>of</token>
      <token>Wales</token>
    </sentence>
    <sentence>
      <token>After</token>
      <token>1295</token>
      <token>and</token>
      <token>the</token>
      <token>final</token>
      <token>Welsh</token>
      <token>War</token>
      <token>of</token>
      <token>the</token>
      <token>thirteenth</token>
      <token>century</token>
      <token>the</token>
      <token>castle</token>
      <token>became</token>
      <token>more</token>
      <token>of</token>
      <token>a</token>
      <token>military</token>
      <token>backwater</token>
      <token>and</token>
      <token>prison</token>
      <token>than</token>
      <token>a</token>
      <token>front</token>
      <token>line</token>
      <token>fortress</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d04.txt">
  <sentences>
    <sentence>
      <token>The</token>
      <token>Antikythera</token>
      <token>mechanism</token>
      <token>is</token>
      <token>an</token>
      <token>ancient</token>
      <token>analog</token>
      <token>computer</token>
      <token>designed</token>
      <token>to</token>
      <token>predict</token>
      <token>astronomical</token>
      <token>positions</token>
      <token>and</token>
      <token>eclipses</token>
      <token>for</token>
      <token>calendrical</token>
      <token>and</token>
      <token>astrological</token>
      <token>purposes</token>
      <token>,</token>
      <token>as</token>
      <token>well</token>
      <token>as</token>
      <token>the</token>
      <token>cycles</token>
      <token>of</token>
      <token>Olympic</token>
      <token>Games</token>
    </sentence>
    <sentence>
      <token>Found</token>
      <token>housed</token>
      <token>in</token>
      <token>a</token>
      <token>340</token>
      <token>×</token>
      <token>180</token>
      <token>×</token>
      <token>90</token>
      <token>mm</token>
      <token>wooden</token>
      <token>box</token>
      <token>,</token>
      <token>the</token>
      <token>device</token>
      <token>is</token>
      <token>a</token>
      <token>complex</token>
      <token>clockwork</token>
      <token>mechanism</token>
      <token>composed</token>
      <token>of</token>
      <token>at</token>
      <token>least</token>
      <token>30</token>
      <token>meshing</token>
      <token>bronze</token>
      <token>gears</token>
    </sentence>
    <sentence>
      <token>Its</token>
      <token>remains</token>
      <token>were</token>
      <token>found</token>
      <token>as</token>
      <token>82</token>
      <token>separate</token>
      <token>fragments</token>
      <token>,</token>
      <token>of</token>
      <token>which</token>
      <token>only</token>
      <token>seven</token>
      <token>contain</token>
      <token>any</token>
      <token>gears</token>
      <token>or</token>
      <token>significant</token>
      <token>inscriptions</token>
    </sentence>
    <sentence>
      <token>The</token>
      <token>largest</token>
      <token>gear</token>
      <token>is</token>
      <token>approximately</token>
      <token>140</token>
      <token>mm</token>
      <token>in</token>
      <token>diameter</token>
    </sentence>
    <sentence>
      <token>The</token>
      <token>artifact</token>
      <token>was</token>
      <token>recovered</token>
      <token>in</token>
      <token>1901</token>
      <token>from</token>
      <token>the</token>
      <token>Antikythera</token>
      <token>shipwreck</token>
      <token>off</token>
      <token>the</token>
      <token>Greek</token>
      <token>island</token>
      <token>of</token>
      <token>Antikythera</token>
    </sentence>
    <sentence>
      <token>Believed</token>
      <token>to</token>
      <token>have</token>
      <token>been</token>
      <token>designed</token>
      <token>and</token>
      <token>constructed</token>
      <token>by</token>
      <token>Greek</token>
      <token>scientists</token>
      <token>,</token>
      <token>the</token>
      <token>instrument</token>
      <token>has</token>
      <token>been</token>
      <token>dated</token>
      <token>either</token>
      <token>between</token>
      <token>150</token>
      <token>to</token>
      <token>100</token>
      <token>BC</token>
      <token>or</token>
      <token>,</token>
      <token>according</token>
      <token>to</token>
      <token>a</token>
      <token>more</token>
      <token>recent</token>
      <token>view</token>
      <token>,</token>
      <token>at</token>
      <token>205</token>
      <token>BC</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d05.txt">
  <sentences>
    <sentence>
      <token>Horseshoe</token>
      <token>crabs</token>
      <token>are</token>
      <token>marine</token>
      <token>arthropods</token>
      <token>that</token>
      <token>live</token>
      <token>primarily</token>
      <token>in</token>
      <token>and</token>
      <token>around</token>
      <token>shallow</token>
      <token>ocean</token>
      <token>waters</token>
      <token>on</token>
      <token>soft</token>
      <token>sandy</token>
      <token>or</token>
      <token>muddy</token>
      <token>bottoms</token>
    </sentence>
    <sentence>
      <token>They</token>
      <token>occasionally</token>
      <token>come</token>
      <token>onto</token>
      <token>shore</token>
      <token>to</token>
      <token>mate</token>
    </sentence>
    <sentence>
      <token>They</token>
      <token>are</token>
      <token>commonly</token>
      <token>used</token>
      <token>as</token>
      <token>bait</token>
      <token>and</token>
      <token>in</token>
      <token>fertilizer</token>
    </sentence>
    <sentence>
      <token>In</token>
      <token>recent</token>
      <token>years</token>
      <token>,</token>
      <token>a</token>
      <token>decline</token>
      <token>in</token>
      <token>the</token>
      <token>population</token>
      <token>has</token>
      <token>occurred</token>
      <token>as</token>
      <token>a</token>
      <token>consequence</token>
      <token>of</token>
      <token>coastal</token>
      <token>habitat</token>
      <token>destruction</token>
      <token>in</token>
      <token>Japan</token>
      <token>and</token>
      <token>overharvesting</token>
      <token>along</token>
      <token>the</token>
      <token>east</token>
      <token>coast</token>
      <token>of</token>
      <token>North</token>
      <token>America</token>
    </sentence>
    <sentence>
      <token>Because</token>
      <token>of</token>
      <token>their</token>
      <token>origin</token>
      <token>450</token>
      <token>million</token>
      <token>years</token>
      <token>ago</token>
      <token>(</token>
      <token>Mya</token>
      <token>)</token>
      <token>),</token>
      <token>horseshoe</token>
      <token>crabs</token>
      <token>are</token>
      <token>considered</token>
      <token>living</token>
      <token>fossils</token>
    </sentence>
    <sentence>
      <token>Horseshoe</token>
      <token>crabs</token>
      <token>resemble</token>
      <token>crustaceans</token>
      <token>,</token>
      <token>but</token>
      <token>belong</token>
      <token>to</token>
      <token>a</token>
      <token>separate</token>
      <token>subphylum</token>
      <token>,</token>
      <token>and</token>
      <token>are</token>
      <token>closely</token>
      <token>related</token>
      <token>to</token>
      <token>arachnids</token>
    </sentence>
    <sentence>
      <token>The</token>
      <token>earliest</token>
      <token>horseshoe</token>
      <token>crab</token>
      <token>fossils</token>
      <token>are</token>
      <token>found</token>
      <token>in</token>
      <token>strata</token>
      <token>from</token>
      <token>the</token>
      <token>late</token>
      <token>Ordovician</token>
      <token>period</token>
      <token>,</token>
      <token>roughly</token>
      <token>450</token>
      <token>Mya</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d06.txt">
  <sentences>
    <sentence>
      <token>A</token>
      <token>differentiable</token>
      <token>manifold</token>
      <token>is</token>
      <token>a</token>
      <token>type</token>
      <token>of</token>
      <token>manifold</token>
      <token>that</token>
      <token>is</token>
      <token>locally</token>
      <token>similar</token>
      <token>enough</token>
      <token>to</token>
      <token>a</token>
      <token>linear</token>
      <token>space</token>
      <token>to</token>
      <token>allow</token>
      <token>one</token>
      <token>to</token>
      <token>do</token>
      <token>calculus</token>
    </sentence>
    <sentence>
      <token>Any</token>
      <token>manifold</token>
      <token>can</token>
      <token>be</token>
      <token>described</token>
      <token>by</token>
      <token>a</token>
      <token>collection</token>
      <token>of</token>
      <token>charts</token>
      <token>,</token>
      <token>also</token>
      <token>known</token>
      <token>as</token>
      <token>an</token>
      <token>atlas</token>
    </sentence>
    <sentence>
      <token>One</token>
      <token>may</token>
      <token>then</token>
      <token>apply</token>
      <token>ideas</token>
      <token>from</token>
      <token>calculus</token>
      <token>while</token>
      <token>working</token>
      <token>within</token>
      <token>the</token>
      <token>individual</token>
      <token>charts</token>
      <token>,</token>
      <token>since</token>
      <token>each</token>
      <token>chart</token>
      <token>lies</token>
      <token>within</token>
      <token>a</token>
      <token>linear</token>
      <token>space</token>
      <token>to</token>
      <token>which</token>
      <token>the</token>
      <token>usual</token>
      <token>rules</token>
      <token>of</token>
      <token>calculus</token>
      <token>apply</token>
    </sentence>
    <sentence>
      <token>If</token>
      <token>the</token>
      <token>charts</token>
      <token>are</token>
      <token>suitably</token>
      <token>compatible</token>
      <token>(</token>
      <token>namely</token>
      <token>,</token>
      <token>the</token>
      <token>transition</token>
      <token>from</token>
      <token>one</token>
      <token>chart</token>
      <token>to</token>
      <token>another</token>
      <token>is</token>
      <token>differentiable</token>
      <token>)</token>
      <token>),</token>
      <token>then</token>
      <token>computations</token>
      <token>done</token>
      <token>in</token>
      <token>one</token>
      <token>chart</token>
      <token>are</token>
      <token>valid</token>
      <token>in</token>
      <token>any</token>
      <token>other</token>
      <token>differentiable</token>
      <token>chart</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d07.txt">
  <sentences>
    <sentence>
      <token>Sun</token>
      <token>Microsystems</token>
      <token>,</token>
      <token>Inc</token>
    </sentence>
    <sentence>
      <token>was</token>
      <token>a</token>
      <token>company</token>
      <token>that</token>
      <token>sold</token>
      <token>computers</token>
      <token>,</token>
      <token>computer</token>
      <token>components</token>
      <token>,</token>
      <token>computer</token>
      <token>software</token>
      <token>,</token>
      <token>and</token>
      <token>information</token>
      <token>technology</token>
      <token>services</token>
      <token>and</token>
      <token>that</token>
      <token>created</token>
      <token>the</token>
      <token>Java</token>
      <token>programming</token>
      <token>language</token>
      <token>and</token>
      <token>the</token>
      <token>Network</token>
      <token>File</token>
      <token>System</token>
      <token>(</token>
      <token>NFS</token>
      <token>)</token>
    </sentence>
    <sentence>
      <token>Sun</token>
      <token>significantly</token>
      <token>evolved</token>
      <token>several</token>
      <token>key</token>
      <token>computing</token>
      <token>technologies</token>
      <token>,</token>
      <token>among</token>
      <token>them</token>
      <token>Unix</token>
      <token>,</token>
      <token>RISC</token>
      <token>processors</token>
      <token>,</token>
      <token>thin</token>
      <token>client</token>
      <token>computing</token>
      <token>,</token>
      <token>and</token>
      <token>virtualized</token>
      <token>computing</token>
    </sentence>
    <sentence>
      <token>Sun</token>
      <token>was</token>
      <token>founded</token>
      <token>on</token>
      <token>February</token>
      <token>24</token>
      <token>,</token>
      <token>1982</token>
    </sentence>
    <sentence>
      <token>On</token>
      <token>January</token>
      <token>27</token>
      <token>,</token>
      <token>2010</token>
      <token>,</token>
      <token>Sun</token>
      <token>was</token>
      <token>acquired</token>
      <token>by</token>
      <token>Oracle</token>
      <token>Corporation</token>
      <token>for</token>
      <token>US</token>
      <token>$7</token>
    </sentence>
    <sentence>
      <token>4</token>
      <token>billion</token>
    </sentence>
    <sentence>
      <token>The</token>
      <token>following</token>
      <token>month</token>
      <token>,</token>
      <token>Sun</token>
      <token>was</token>
      <token>merged</token>
      <token>with</token>
      <token>Oracle</token>
      <token>USA</token>
      <token>,</token>
      <token>Inc</token>
    </sentence>
    <sentence>
      <token>to</token>
      <token>become</token>
      <token>Oracle</token>
      <token>America</token>
      <token>,</token>
      <token>Inc</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d08.txt">
  <sentences>
    <sentence>
      <token>Apollo</token>
      <token>11</token>
      <token>was</token>
      <token>the</token>
      <token>spaceflight</token>
      <token>that</token>
      <token>landed</token>
      <token>the</token>
      <token>first</token>
      <token>humans</token>
      <token>on</token>
      <token>the</token>
      <token>Moon</token>
      <token>,</token>
      <token>Americans</token>
      <token>Neil</token>
      <token>Armstrong</token>
      <token>and</token>
      <token>Buzz</token>
      <token>Aldrin</token>
      <token>,</token>
      <token>on</token>
      <token>July</token>
      <token>20</token>
      <token>,</token>
      <token>1969</token>
    </sentence>
    <sentence>
      <token>Armstrong</token>
      <token>became</token>
      <token>the</token>
      <token>first</token>
      <token>to</token>
      <token>step</token>
      <token>onto</token>
      <token>the</token>
      <token>lunar</token>
      <token>surface</token>
      <token>six</token>
      <token>hours</token>
      <token>later</token>
    </sentence>
    <sentence>
      <token>Armstrong</token>
      <token>spent</token>
      <token>about</token>
      <token>two</token>
      <token>and</token>
      <token>a</token>
      <token>half</token>
      <token>hours</token>
      <token>outside</token>
      <token>the</token>
      <token>spacecraft</token>
      <token>,</token>
      <token>Aldrin</token>
      <token>slightly</token>
      <token>less</token>
      <token>,</token>
      <token>and</token>
      <token>together</token>
      <token>they</token>
      <token>collected</token>
      <token>47</token>
    </sentence>
    <sentence>
      <token>5</token>
      <token>pounds</token>
      <token>(</token>
      <token>21</token>
    </sentence>
    <sentence>
      <token>5</token>
      <token>kg</token>
      <token>)</token>
      <token>of</token>
      <token>lunar</token>
      <token>material</token>
      <token>for</token>
      <token>return</token>
      <token>to</token>
      <token>Earth</token>
    </sentence>
    <sentence>
      <token>The</token>
      <token>third</token>
      <token>member</token>
      <token>of</token>
      <token>the</token>
      <token>mission</token>
      <token>,</token>
      <token>Michael</token>
      <token>Collins</token>
      <token>,</token>
      <token>piloted</token>
      <token>the</token>
      <token>command</token>
      <token>spacecraft</token>
      <token>alone</token>
      <token>in</token>
      <token>lunar</token>
      <token>orbit</token>
      <token>until</token>
      <token>Armstrong</token>
      <token>and</token>
      <token>Aldrin</token>
      <token>returned</token>
      <token>to</token>
      <token>it</token>
      <token>just</token>
      <token>under</token>
      <token>a</token>
      <token>day</token>
      <token>later</token>
      <token>for</token>
      <token>the</token>
      <token>trip</token>
      <token>back</token>
      <token>to</token>
      <token>Earth</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d09.txt">
  <sentences>
    <sentence>
      <token>The</token>
      <token>Apollo</token>
      <token>spacecraft</token>
      <token>had</token>
      <token>three</token>
      <token>parts:</token>
      <token>a</token>
      <token>Command</token>
      <token>Module</token>
      <token>with</token>
      <token>a</token>
      <token>cabin</token>
      <token>for</token>
      <token>the</token>
      <token>three</token>
      <token>astronauts</token>
      <token>,</token>
      <token>and</token>
      <token>the</token>
      <token>only</token>
      <token>part</token>
      <token>that</token>
      <token>landed</token>
      <token>back</token>
      <token>on</token>
      <token>Earth;</token>
      <token>a</token>
      <token>Service</token>
      <token>Module</token>
      <token>,</token>
      <token>which</token>
      <token>supported</token>
      <token>the</token>
      <token>Command</token>
      <token>Module</token>
      <token>with</token>
      <token>propulsion</token>
      <token>,</token>
      <token>electrical</token>
      <token>power</token>
      <token>,</token>
      <token>oxygen</token>
      <token>,</token>
      <token>and</token>
      <token>water;</token>
      <token>and</token>
      <token>a</token>
      <token>Lunar</token>
      <token>Module</token>
      <token>for</token>
      <token>landing</token>
      <token>on</token>
      <token>the</token>
      <token>Moon</token>
    </sentence>
    <sentence>
      <token>After</token>
      <token>being</token>
      <token>sent</token>
      <token>toward</token>
      <token>the</token>
      <token>Moon</token>
      <token>by</token>
      <token>the</token>
      <token>Saturn</token>
      <token>V</token>
      <token>'</token>
      <token>s</token>
      <token>upper</token>
      <token>stage</token>
      <token>,</token>
      <token>the</token>
      <token>astronauts</token>
      <token>separated</token>
      <token>the</token>
      <token>spacecraft</token>
      <token>from</token>
      <token>it</token>
      <token>and</token>
      <token>traveled</token>
      <token>for</token>
      <token>three</token>
      <token>days</token>
      <token>until</token>
      <token>they</token>
      <token>entered</token>
      <token>into</token>
      <token>lunar</token>
      <token>orbit</token>
    </sentence>
    <sentence>
      <token>Armstrong</token>
      <token>and</token>
      <token>Aldrin</token>
      <token>then</token>
      <token>moved</token>
      <token>into</token>
      <token>the</token>
      <token>Lunar</token>
      <token>Module</token>
      <token>and</token>
      <token>landed</token>
      <token>in</token>
      <token>the</token>
      <token>Sea</token>
      <token>of</token>
      <token>Tranquility</token>
    </sentence>
    <sentence>
      <token>They</token>
      <token>stayed</token>
      <token>a</token>
      <token>total</token>
      <token>of</token>
      <token>about</token>
      <token>21</token>
    </sentence>
    <sentence>
      <token>5</token>
      <token>hours</token>
      <token>on</token>
      <token>the</token>
      <token>lunar</token>
      <token>surface</token>
    </sentence>
    <sentence>
      <token>After</token>
      <token>lifting</token>
      <token>off</token>
      <token>in</token>
      <token>the</token>
      <token>upper</token>
      <token>part</token>
      <token>of</token>
      <token>the</token>
      <token>Lunar</token>
      <token>Module</token>
      <token>and</token>
      <token>rejoining</token>
      <token>Collins</token>
      <token>in</token>
      <token>the</token>
      <token>Command</token>
      <token>Module</token>
      <token>,</token>
      <token>they</token>
      <token>returned</token>
      <token>to</token>
      <token>Earth</token>
      <token>and</token>
      <token>landed</token>
      <token>in</token>
      <token>the</token>
      <token>Pacific</token>
      <token>Ocean</token>
      <token>on</token>
      <token>July</token>
      <token>24</token>
    </sentence>
  </sentences>
</file>
<file filename="nlp_data/d10.txt">
  <sentences>
    <sentence>
      <token>James</token>
      <token>Clerk</token>
      <token>Maxwell</token>
      <token>was</token>
      <token>a</token>
      <token>Scottish</token>
      <token>mathematical</token>
      <token>physicist</token>
    </sentence>
    <sentence>
      <token>His</token>
      <token>most</token>
      <token>notable</token>
      <token>achievement</token>
      <token>was</token>
      <token>to</token>
      <token>formulate</token>
      <token>the</token>
      <token>classical</token>
      <token>theory</token>
      <token>of</token>
      <token>electromagnetic</token>
      <token>radiation</token>
      <token>,</token>
      <token>bringing</token>
      <token>together</token>
      <token>for</token>
      <token>the</token>
      <token>first</token>
      <token>time</token>
      <token>electricity</token>
      <token>,</token>
      <token>magnetism</token>
      <token>,</token>
      <token>and</token>
      <token>light</token>
      <token>as</token>
      <token>manifestations</token>
      <token>of</token>
      <token>the</token>
      <token>same</token>
      <token>phenomenon</token>
    </sentence>
    <sentence>
      <token>Maxwell</token>
      <token>'</token>
      <token>s</token>
      <token>equations</token>
      <token>for</token>
      <token>electromagnetism</token>
      <token>have</token>
      <token>been</token>
      <token>called</token>
      <token>the</token>
      <token>"</token>
      <token>second</token>
      <token>great</token>
      <token>unification</token>
      <token>in</token>
      <token>physics</token>
      <token>"</token>
      <token>after</token>
      <token>the</token>
      <token>first</token>
      <token>one</token>
      <token>realised</token>
      <token>by</token>
      <token>Isaac</token>
      <token>Newton</token>
      <token>...</token>
      <token>Maxwell</token>
      <token>demonstrated</token>
      <token>that</token>
      <token>electric</token>
      <token>and</token>
      <token>magnetic</token>
      <token>fields</token>
      <token>travel</token>
      <token>through</token>
      <token>space</token>
      <token>as</token>
      <token>waves</token>
      <token>moving</token>
      <token>at</token>
      <token>the</token>
      <token>speed</token>
      <token>of</token>
      <token>light</token>
    </sentence>
    <sentence>
      <token>Maxwell</token>
      <token>proposed</token>
      <token>that</token>
      <token>light</token>
      <token>is</token>
      <token>an</token>
      <token>undulation</token>
      <token>in</token>
      <token>the</token>
      <token>same</token>
      <token>medium</token>
      <token>that</token>
      <token>is</token>
      <token>the</token>
      <token>cause</token>
      <token>of</token>
      <token>electric</token>
      <token>and</token>
      <token>magnetic</token>
      <token>phenomena</token>
    </sentence>
    <sentence>
      <token>The</token>
      <token>unification</token>
      <token>of</token>
      <token>light</token>
      <token>and</token>
      <token>electrical</token>
      <token>phenomena</token>
      <token>led</token>
      <token>to</token>
      <token>the</token>
      <token>prediction</token>
      <token>of</token>
      <token>the</token>
      <token>existence</token>
      <token>of</token>
      <token>radio</token>
      <token>waves</token>
    </sentence>
    <sentence>
      <token>His</token>
      <token>discoveries</token>
      <token>helped</token>
      <token>usher</token>
      <token>in</token>
      <token>the</token>
      <token>era</token>
      <token>of</token>
      <token>modern</token>
      <token>physics</token>
      <token>,</token>
      <token>laying</token>
      <token>the</token>
      <token>foundation</token>
      <token>for</token>
      <token>such</token>
      <token>fields</token>
      <token>as</token>
      <token>special</token>
      <token>relativity</token>
      <token>and</token>
      <token>quantum</token>
      <token>mechanics</token>
    </sentence>
    <sentence>
      <token>His</token>
      <token>contributions</token>
      <token>to</token>
      <token>the</token>
      <token>science</token>
      <token>are</token>
      <token>considered</token>
      <token>by</token>
      <token>many</token>
      <token>to</token>
      <token>be</token>
      <token>of</token>
      <token>the</token>
      <token>same</token>
      <token>magnitude</token>
      <token>as</token>
      <token>those</token>
      <token>of</token>
      <token>Isaac</token>
      <token>Newton</token>
      <token>and</token>
      <token>Albert</token>
      <token>Einstein</token>
    </sentence>
    <sentence>
      <token>QED</token>
    </sentence>
  </sentences>
</file>

